{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSION\n",
    "\n",
    "In this notebook, `ElasticNet` Regression is done which combines L1 and L2 penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import style\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "from Data_Preprocessing import *\n",
    "import pickle\n",
    "import glob \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "# Configuraci√≥n matplotlib\n",
    "# ==============================================================================\n",
    "plt.rcParams['image.cmap'] = \"bwr\"\n",
    "#plt.rcParams['figure.dpi'] = \"100\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "style.use('ggplot') or plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Getting Scores\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting parent directory\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir) \n",
    "\n",
    "#getting data\n",
    "mat_path = parentdir+'/Feature_Extraction/DATA/FC_Stroke/FCMatrixImage_131subj.mat'\n",
    "lang_path = parentdir+'/Feature_Extraction/DATA/FC_Stroke/language_score.xlsx'\n",
    "\n",
    "#we take both the fc matrices and the languages scores even if we dont use the FC matrices---here we only care about the scores\n",
    "fc_3d, language_score, ID = get_arrays(mat_path, lang_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Importing features\n",
    "---\n",
    "\n",
    "Given the method, we will import the features and weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i.e now importing PCA features: choose the directory according to import the correct feat\n",
    "feats = open(parentdir+\"/Results/Results_Extractors/PCA_RESULTS/FEATURES_PCA.pkl\", \"rb\")\n",
    "features_PCA = pickle.load(feats)\n",
    "\n",
    "weights = open(parentdir+\"/Results/Results_Extractors/PCA_RESULTS/WEIGHTS_PCA.pkl\", \"rb\")\n",
    "W_PCA = pickle.load(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Removing empty scores values\n",
    "\n",
    "---\n",
    "Since now we care about the availability of the scores, we will now remove those features that has no correspondent scores. Furthremore, the features and the scores are standarize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_Preparation import data_cleansing\n",
    "features, scores = data_cleansing(language_score, features_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standarizing everything\n",
    "scores_scaled = (scores - scores.mean())/scores.std()\n",
    "\n",
    "for key in features.keys():\n",
    "    for i in range(len(features[key].T)):\n",
    "        features[key].T[i] = (features[key].T[i] -  np.mean(features[key], 1))/ np.std(features[key], 1)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 ElasticNet Regression\n",
    "\n",
    "---\n",
    "\n",
    "Following the paper, we will perfomed elasticnet regression. Notice that the difference between the matlab function and the python one is in the definition of the alphas and lambdas (they are the opposite). \n",
    "Now, the optimal parameter are obtained by means of leave one out. IN particular we will use the `LeaveOneOut` function available from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter search\n",
    "alphas = np.logspace(-5, 5, 100)\n",
    "lambdas =  [0.001, 0.25, 0.5, 0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticnet(xtr, ytr, xte, yte, alph,l ):\n",
    "    modelo = ElasticNet(\n",
    "            l1_ratio        = l,\n",
    "            alpha          = alph,\n",
    "            normalize       = False,\n",
    "            max_iter = 100000\n",
    "         )\n",
    "    modelo.fit(xtr, ytr)\n",
    "    ypred = modelo.predict(xte)\n",
    "    coef = modelo.coef_\n",
    "    return ypred, coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_lambda(Xtr, ytr, Xte, yte, ALPHA, LAMBDAS):\n",
    "    \n",
    "    nlamb = len(LAMBDAS)\n",
    "    y_lamb = np.zeros (nlamb) \n",
    "    mse_lamb = np.zeros (nlamb) \n",
    "    coeficientes = np.zeros([ nlamb,Xtr.shape[1]])\n",
    "\n",
    "    for idx_l, lamd in enumerate(LAMBDAS):\n",
    "        \n",
    "        y_pred, coef_ = elasticnet(Xtr, ytr, Xte, yte, ALPHA, lamd)\n",
    "        coeficientes[idx_l,:] = coef_\n",
    "        y_lamb[idx_l] = y_pred\n",
    "        mse_lamb[idx_l] = ((yte - y_pred)**2)\n",
    "        \n",
    "    return y_lamb, mse_lamb, coeficientes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_alpha(X_train_, y_train_, X_test_, y_test_, alp, lambdas_):\n",
    "    nalpha = len(alp)\n",
    "    nlamb = len(lambdas_)\n",
    "    y_alp = np.zeros([nlamb, nalpha])\n",
    "    mse_alp = np.zeros([nlamb, nalpha])\n",
    "    Coeficient = np.zeros([nalpha, nlamb, X_train_.shape[1]])\n",
    "\n",
    "\n",
    "    for i_al, alfas in enumerate(alp):\n",
    "        y_lamb_, mse_lamb_,coeficientes_  = opt_lambda(X_train_, y_train_, X_test_, y_test_, alfas, lambdas_)\n",
    "        y_alp[:,i_al] = y_lamb_\n",
    "        mse_alp[:,i_al] =mse_lamb_\n",
    "        Coeficient[i_al,:,:] = coeficientes_\n",
    "    return y_alp, mse_alp, Coeficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loocv(X, y, alphas, lambdas):\n",
    "    nalpha = len(alphas)\n",
    "    nlamb = len(lambdas)\n",
    "    npca = len(features)\n",
    "    n_subj = len(features['n10'])\n",
    "    \n",
    "    y_hat = np.zeros([nlamb, nalpha, npca,n_subj])\n",
    "    MSE = np.zeros([nlamb, nalpha, npca])\n",
    "    \n",
    "    loo = LeaveOneOut()\n",
    "    loo.get_n_splits(X)\n",
    "    coefi = []\n",
    "\n",
    "    idx = 0\n",
    "    for key in tqdm(features.keys()):\n",
    "        X = features[key]\n",
    "        y = scores\n",
    "        \n",
    "        subj_idx = 0\n",
    "        sum_coef = np.zeros([nalpha,nlamb,X.shape[1]])\n",
    "\n",
    "        for train_index, test_index in loo.split(X):\n",
    "        \n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        \n",
    "            y_alp_, mse_alp_, coefic_ = opt_alpha(X_train, y_train, X_test, y_test, alphas , lambdas)\n",
    "            \n",
    "            y_hat[:,:,idx,subj_idx] = y_alp_\n",
    "            \n",
    "            MSE[:,:,idx] += mse_alp_\n",
    "            sum_coef +=coefic_\n",
    "            subj_idx +=1\n",
    "        print(MSE[:,:,idx].min()/n_subj)  \n",
    "        idx +=1\n",
    "        coefi.append(sum_coef)\n",
    "    return y_hat, MSE, coefi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing loocv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, MSE, coefi = loocv(features, scores_scaled,  alphas, lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Analysis of the model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##getting best values\n",
    "#diving the mean squared error with the total number of subject\n",
    "MSE /= len(features['n10'])\n",
    "\n",
    "#getting best (meaning mininum MSE) value\n",
    "l_indeces = []\n",
    "a_indeces = []\n",
    "f_indeces = []\n",
    "\n",
    "for lamb_idx in range(len(MSE)):\n",
    "    for alph_idx in range(len(MSE[0])):\n",
    "        for n_features in range(len(MSE[0][0])):\n",
    "            if (MSE.min() == MSE[lamb_idx,alph_idx,n_features]):\n",
    "                best_lambda = lambdas[lamb_idx]\n",
    "                best_alpha = alphas[alph_idx]\n",
    "                best_feat = list(features.keys())[n_features]\n",
    "                print(\"Best lambda\", lambdas[lamb_idx], \n",
    "                      \", Best Alpha\", alphas[alph_idx], \n",
    "                      \", Best N_component\", list(features.keys())[n_features], \n",
    "                     \", MSE\", MSE.min())\n",
    "                l_indeces.append(lamb_idx)\n",
    "                a_indeces.append(alph_idx)\n",
    "                f_indeces.append(n_features)\n",
    "                \n",
    "#best y and best coeficients\n",
    "best_y =  y_hat[l_indeces[0], a_indeces[0], f_indeces[0], :]\n",
    "best_coef = coefi[f_indeces[0]][a_indeces[0]][l_indeces[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving \n",
    "MODELS  = ['AUGMENTATED','CONV AE', 'ICA', 'One linear layer AE', 'Non linear layer AE', 'PCA', 'TRANSFER']\n",
    "model = MODELS[5]\n",
    "np.save('RESULTS/Y_pred_'+str(model), y_hat)\n",
    "np.save('RESULTS/MSE_'+str(model), MSE)\n",
    "np.save('RESULTS/Best_Coeficients_'+str(model), best_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get R^2 for best model\n",
    "y = scores_scaled \n",
    "sse = sum((best_y - y)**2)\n",
    "sst = sum((y - np.mean(y))**2)\n",
    "R_2 = 1 - sse / sst;\n",
    "print(\"R squared:\", R_2)\n",
    "\n",
    "#get BIC value  for best model\n",
    "ns = len(y);\n",
    "nzc = np.sum(best_coef != 0)\n",
    "bic = ns + ns * np.log(2*np.pi) + ns * np.log(sse/ns) + np.log(ns) * nzc;\n",
    "print(\"BIC:\", bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving best values\n",
    "pca_fold = pd.DataFrame({'$R^2$': R_2,\n",
    "              'MSE': MSE.min(),\n",
    "              'BIC': bic, \n",
    "              'Best Lambda': best_lambda,\n",
    "              'Best Alpha': best_alpha,\n",
    "              'Best Fold': best_feat,\n",
    "               'NZ': nzc},  index=[str(model)])\n",
    "\n",
    "pca_fold.to_csv('RESULTS/'+str(model)+'.csv')"
   ]
  },
  
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
